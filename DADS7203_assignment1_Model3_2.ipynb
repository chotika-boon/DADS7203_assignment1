{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chotika-boon/DADS7203_assignment1/blob/main/DADS7203_assignment1_Model3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Research"
      ],
      "metadata": {
        "id": "H-285_sHVINS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/ <br>\n",
        "https://pytorch.org/hub/huggingface_pytorch-transformers/<br>\n",
        "https://huggingface.co/transformers/quicktour.html"
      ],
      "metadata": {
        "id": "hx1saO0tVOMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install Library"
      ],
      "metadata": {
        "id": "Qq4jID3xHgvi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY3XWjbPG-iW",
        "outputId": "a1777c59-c266-41ee-8401-afccce99c0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uywMIxSo1i28",
        "outputId": "6bdba360-480d-41de-9299-7e7bf30100e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "DquIUKnFHm3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from google.colab import widgets"
      ],
      "metadata": {
        "id": "6irvG9Vn1ZR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load Data"
      ],
      "metadata": {
        "id": "gweOJNL6UV6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/lab/tcas61-2.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1TalNJjHPdD",
        "outputId": "f5b3c2d9-38ba-49d2-de51-7441c3189c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  มึงกล้าพูดรึป่าวว่าระบบการศึกษามันดีอ่ะ ถุ้ยเฟ...\n",
              "1      0  เบื่อเวลามาโพสตไรแบบนี้ชอบเป็นพวกที่ใช่โปรไฟล์...\n",
              "2      0  พ่อมึงเป็นติ่งรัฐบาลหรอสัส ที่เรียกเก็บตังแพงม...\n",
              "3      0  ใครก็ช่วยลบไอ้นี้ออกจากกลุ่มหน่อยครับ มันมาโพส...\n",
              "4      0                                  เครียดมากอะตอนนี้"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-326c88dd-c951-405f-8012-3e3116e87829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>มึงกล้าพูดรึป่าวว่าระบบการศึกษามันดีอ่ะ ถุ้ยเฟ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>เบื่อเวลามาโพสตไรแบบนี้ชอบเป็นพวกที่ใช่โปรไฟล์...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>พ่อมึงเป็นติ่งรัฐบาลหรอสัส ที่เรียกเก็บตังแพงม...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>ใครก็ช่วยลบไอ้นี้ออกจากกลุ่มหน่อยครับ มันมาโพส...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>เครียดมากอะตอนนี้</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-326c88dd-c951-405f-8012-3e3116e87829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-326c88dd-c951-405f-8012-3e3116e87829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-326c88dd-c951-405f-8012-3e3116e87829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvCKqUvXIZb1",
        "outputId": "c61b57f1-8b08-4917-f202-7e7de3aa05ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGYCAYAAADiAIAsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcgElEQVR4nO3df2xd9X3/8Zfzy8kIvmkC2EQ4kG10gbYwGrrEwGiXessihBLFakvFNn5EY+1cNhJ1DEv8aBHUgFqSpcuPFaUB1GasSIOVVQ1qPTVdVScEM1i7bild08VbsBnbYkOqOBHx94+q91uX0PYmzsdx8nhIR+J+zrnHb0sYPzn3XN+64eHh4QAAFDJhrAcAAE4t4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIqaNNYD/LTDhw9n7969Of3001NXVzfW4wAAv4Dh4eG8+uqrmT17diZM+NnXNk64+Ni7d2+am5vHegwA4Cj09vbmnHPO+ZnHnHDxcfrppyf50fANDQ1jPA0A8IsYHBxMc3Nz9ff4z3LCxcePX2ppaGgQHwAwzvwit0y44RQAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUNSkWg5+/fXX87GPfSyf+9zn0tfXl9mzZ+f666/P7bffXv0I3eHh4dx111156KGHsm/fvlx++eXZsGFDzj///OPyDZxMzrvtS2M9AgX94L6rxnoEgDFR05WP+++/Pxs2bMhf/uVf5l//9V9z//3354EHHsinP/3p6jEPPPBA1q5dm40bN2bHjh057bTTsnjx4hw4cGDUhwcAxp+arnx885vfzNKlS3PVVT/6P7bzzjsvf/3Xf51nnnkmyY+ueqxZsya33357li5dmiR59NFH09jYmCeffDLXXHPNKI8PAIw3NV35uOyyy9LV1ZXvfve7SZIXXngh3/jGN7JkyZIkye7du9PX15fW1tbqcyqVShYsWJDu7u5RHBsAGK9quvJx2223ZXBwMPPmzcvEiRPz+uuv59577821116bJOnr60uSNDY2jnheY2Njdd9PGxoaytDQUPXx4OBgTd8AADC+1HTl4wtf+EI+//nPZ8uWLXnuuefyyCOP5JOf/GQeeeSRox6gs7MzlUqlujU3Nx/1uQCAE19N8fFnf/Znue2223LNNdfkHe94R37/938/K1euTGdnZ5KkqakpSdLf3z/ief39/dV9P62joyMDAwPVrbe392i+DwBgnKgpPn74wx9mwoSRT5k4cWIOHz6cJJk7d26amprS1dVV3T84OJgdO3akpaXliOesr69PQ0PDiA0AOHnVdM/H1VdfnXvvvTdz5szJ2972tvzTP/1THnzwwdx4441Jkrq6utxyyy255557cv7552fu3Lm54447Mnv27Cxbtux4zA8AjDM1xcenP/3p3HHHHfnjP/7jvPzyy5k9e3b+6I/+KHfeeWf1mFtvvTX79+/PTTfdlH379uWKK67I1q1bM3Xq1FEfHgAYf+qGh4eHx3qInzQ4OJhKpZKBgYFT7iUYf+H01OIvnAInk1p+f/tsFwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoKia4uO8885LXV3dG7b29vYkyYEDB9Le3p5Zs2Zl+vTpaWtrS39//3EZHAAYn2qKj507d+all16qbl/5yleSJO973/uSJCtXrsxTTz2Vxx9/PNu2bcvevXuzfPny0Z8aABi3JtVy8Jlnnjni8X333Zdf+ZVfybvf/e4MDAxk06ZN2bJlSxYtWpQk2bx5cy644IJs3749CxcuHL2pAYBx66jv+Th48GA+97nP5cYbb0xdXV16enpy6NChtLa2Vo+ZN29e5syZk+7u7jc9z9DQUAYHB0dsAMDJ66jj48knn8y+ffty/fXXJ0n6+voyZcqUzJgxY8RxjY2N6evre9PzdHZ2plKpVLfm5uajHQkAGAeOOj42bdqUJUuWZPbs2cc0QEdHRwYGBqpbb2/vMZ0PADix1XTPx4/9x3/8R7761a/mb//2b6trTU1NOXjwYPbt2zfi6kd/f3+ampre9Fz19fWpr68/mjEAgHHoqK58bN68OWeddVauuuqq6tr8+fMzefLkdHV1Vdd27dqVPXv2pKWl5dgnBQBOCjVf+Th8+HA2b96c6667LpMm/f+nVyqVrFixIqtWrcrMmTPT0NCQm2++OS0tLd7pAgBU1RwfX/3qV7Nnz57ceOONb9i3evXqTJgwIW1tbRkaGsrixYuzfv36URkUADg51A0PDw+P9RA/aXBwMJVKJQMDA2loaBjrcYo677YvjfUIFPSD+676+QcBjBO1/P722S4AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAiqo5Pv7rv/4rv/d7v5dZs2Zl2rRpecc73pFnn322un94eDh33nlnzj777EybNi2tra158cUXR3VoAGD8qik+/u///i+XX355Jk+enC9/+cv5zne+k0996lN5y1veUj3mgQceyNq1a7Nx48bs2LEjp512WhYvXpwDBw6M+vAAwPgzqZaD77///jQ3N2fz5s3Vtblz51b/eXh4OGvWrMntt9+epUuXJkkeffTRNDY25sknn8w111wzSmMDAONVTVc+vvjFL+bSSy/N+973vpx11lm55JJL8tBDD1X37969O319fWltba2uVSqVLFiwIN3d3aM3NQAwbtUUH9///vezYcOGnH/++Xn66afz4Q9/OH/yJ3+SRx55JEnS19eXJGlsbBzxvMbGxuq+nzY0NJTBwcERGwBw8qrpZZfDhw/n0ksvzSc+8YkkySWXXJJvf/vb2bhxY6677rqjGqCzszMf//jHj+q5AMD4U9OVj7PPPjsXXnjhiLULLrgge/bsSZI0NTUlSfr7+0cc09/fX9330zo6OjIwMFDdent7axkJABhnaoqPyy+/PLt27Rqx9t3vfjfnnntukh/dfNrU1JSurq7q/sHBwezYsSMtLS1HPGd9fX0aGhpGbADAyauml11WrlyZyy67LJ/4xCfy/ve/P88880w+85nP5DOf+UySpK6uLrfcckvuueeenH/++Zk7d27uuOOOzJ49O8uWLTse8wMA40xN8fGud70rTzzxRDo6OnL33Xdn7ty5WbNmTa699trqMbfeemv279+fm266Kfv27csVV1yRrVu3ZurUqaM+PAAw/tQNDw8Pj/UQP2lwcDCVSiUDAwOn3Esw5932pbEegYJ+cN9VYz0CwKip5fe3z3YBAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKqik+Pvaxj6Wurm7ENm/evOr+AwcOpL29PbNmzcr06dPT1taW/v7+UR8aABi/ar7y8ba3vS0vvfRSdfvGN75R3bdy5co89dRTefzxx7Nt27bs3bs3y5cvH9WBAYDxbVLNT5g0KU1NTW9YHxgYyKZNm7Jly5YsWrQoSbJ58+ZccMEF2b59exYuXHjs0wIA417NVz5efPHFzJ49O7/8y7+ca6+9Nnv27EmS9PT05NChQ2ltba0eO2/evMyZMyfd3d1ver6hoaEMDg6O2ACAk1dN8bFgwYI8/PDD2bp1azZs2JDdu3fnN3/zN/Pqq6+mr68vU6ZMyYwZM0Y8p7GxMX19fW96zs7OzlQqlerW3Nx8VN8IADA+1PSyy5IlS6r/fNFFF2XBggU599xz84UvfCHTpk07qgE6OjqyatWq6uPBwUEBAgAnsWN6q+2MGTPy1re+Nd/73vfS1NSUgwcPZt++fSOO6e/vP+I9Ij9WX1+fhoaGERsAcPI6pvh47bXX8u///u85++yzM3/+/EyePDldXV3V/bt27cqePXvS0tJyzIMCACeHml52+ehHP5qrr7465557bvbu3Zu77rorEydOzAc/+MFUKpWsWLEiq1atysyZM9PQ0JCbb745LS0t3ukCAFTVFB//+Z//mQ9+8IP5n//5n5x55pm54oorsn379px55plJktWrV2fChAlpa2vL0NBQFi9enPXr1x+XwQGA8alueHh4eKyH+EmDg4OpVCoZGBg45e7/OO+2L431CBT0g/uuGusRAEZNLb+/fbYLAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAoiaN9QAAp4LzbvvSWI9AQT+476qxHuGE5soHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUdUzxcd9996Wuri633HJLde3AgQNpb2/PrFmzMn369LS1taW/v/9Y5wQAThJHHR87d+7MX/3VX+Wiiy4asb5y5co89dRTefzxx7Nt27bs3bs3y5cvP+ZBAYCTw1HFx2uvvZZrr702Dz30UN7ylrdU1wcGBrJp06Y8+OCDWbRoUebPn5/Nmzfnm9/8ZrZv3z5qQwMA49dRxUd7e3uuuuqqtLa2jljv6enJoUOHRqzPmzcvc+bMSXd397FNCgCcFGr+bJfHHnsszz33XHbu3PmGfX19fZkyZUpmzJgxYr2xsTF9fX1HPN/Q0FCGhoaqjwcHB2sdCQAYR2q68tHb25s//dM/zec///lMnTp1VAbo7OxMpVKpbs3NzaNyXgDgxFRTfPT09OTll1/OO9/5zkyaNCmTJk3Ktm3bsnbt2kyaNCmNjY05ePBg9u3bN+J5/f39aWpqOuI5Ozo6MjAwUN16e3uP+psBAE58Nb3s8t73vjff+ta3RqzdcMMNmTdvXv78z/88zc3NmTx5crq6utLW1pYk2bVrV/bs2ZOWlpYjnrO+vj719fVHOT4AMN7UFB+nn3563v72t49YO+200zJr1qzq+ooVK7Jq1arMnDkzDQ0Nufnmm9PS0pKFCxeO3tQAwLhV8w2nP8/q1aszYcKEtLW1ZWhoKIsXL8769etH+8sAAOPUMcfH1772tRGPp06dmnXr1mXdunXHemoA4CTks10AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICiaoqPDRs25KKLLkpDQ0MaGhrS0tKSL3/5y9X9Bw4cSHt7e2bNmpXp06enra0t/f39oz40ADB+1RQf55xzTu6777709PTk2WefzaJFi7J06dL8y7/8S5Jk5cqVeeqpp/L4449n27Zt2bt3b5YvX35cBgcAxqdJtRx89dVXj3h87733ZsOGDdm+fXvOOeecbNq0KVu2bMmiRYuSJJs3b84FF1yQ7du3Z+HChaM3NQAwbh31PR+vv/56Hnvssezfvz8tLS3p6enJoUOH0traWj1m3rx5mTNnTrq7u9/0PENDQxkcHByxAQAnr5rj41vf+lamT5+e+vr6fOhDH8oTTzyRCy+8MH19fZkyZUpmzJgx4vjGxsb09fW96fk6OztTqVSqW3Nzc83fBAAwftQcH7/2a7+W559/Pjt27MiHP/zhXHfddfnOd75z1AN0dHRkYGCguvX29h71uQCAE19N93wkyZQpU/Krv/qrSZL58+dn586d+Yu/+It84AMfyMGDB7Nv374RVz/6+/vT1NT0puerr69PfX197ZMDAOPSMf+dj8OHD2doaCjz58/P5MmT09XVVd23a9eu7NmzJy0tLcf6ZQCAk0RNVz46OjqyZMmSzJkzJ6+++mq2bNmSr33ta3n66adTqVSyYsWKrFq1KjNnzkxDQ0NuvvnmtLS0eKcLAFBVU3y8/PLL+YM/+IO89NJLqVQqueiii/L000/nt3/7t5Mkq1evzoQJE9LW1pahoaEsXrw469evPy6DAwDjU03xsWnTpp+5f+rUqVm3bl3WrVt3TEMBACcvn+0CABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoKia4qOzszPvete7cvrpp+ess87KsmXLsmvXrhHHHDhwIO3t7Zk1a1amT5+etra29Pf3j+rQAMD4VVN8bNu2Le3t7dm+fXu+8pWv5NChQ/md3/md7N+/v3rMypUr89RTT+Xxxx/Ptm3bsnfv3ixfvnzUBwcAxqdJtRy8devWEY8ffvjhnHXWWenp6cmVV16ZgYGBbNq0KVu2bMmiRYuSJJs3b84FF1yQ7du3Z+HChaM3OQAwLh3TPR8DAwNJkpkzZyZJenp6cujQobS2tlaPmTdvXubMmZPu7u4jnmNoaCiDg4MjNgDg5HXU8XH48OHccsstufzyy/P2t789SdLX15cpU6ZkxowZI45tbGxMX1/fEc/T2dmZSqVS3Zqbm492JABgHDjq+Ghvb8+3v/3tPPbYY8c0QEdHRwYGBqpbb2/vMZ0PADix1XTPx4995CMfyd///d/n61//es4555zqelNTUw4ePJh9+/aNuPrR39+fpqamI56rvr4+9fX1RzMGADAO1XTlY3h4OB/5yEfyxBNP5B/+4R8yd+7cEfvnz5+fyZMnp6urq7q2a9eu7NmzJy0tLaMzMQAwrtV05aO9vT1btmzJ3/3d3+X000+v3sdRqVQybdq0VCqVrFixIqtWrcrMmTPT0NCQm2++OS0tLd7pAgAkqTE+NmzYkCR5z3veM2J98+bNuf7665Mkq1evzoQJE9LW1pahoaEsXrw469evH5VhAYDxr6b4GB4e/rnHTJ06NevWrcu6deuOeigA4OTls10AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICiao6Pr3/967n66qsze/bs1NXV5cknnxyxf3h4OHfeeWfOPvvsTJs2La2trXnxxRdHa14AYJyrOT7279+fiy++OOvWrTvi/gceeCBr167Nxo0bs2PHjpx22mlZvHhxDhw4cMzDAgDj36Ran7BkyZIsWbLkiPuGh4ezZs2a3H777Vm6dGmS5NFHH01jY2OefPLJXHPNNcc2LQAw7o3qPR+7d+9OX19fWltbq2uVSiULFixId3f3EZ8zNDSUwcHBERsAcPIa1fjo6+tLkjQ2No5Yb2xsrO77aZ2dnalUKtWtubl5NEcCAE4wY/5ul46OjgwMDFS33t7esR4JADiORjU+mpqakiT9/f0j1vv7+6v7flp9fX0aGhpGbADAyWtU42Pu3LlpampKV1dXdW1wcDA7duxIS0vLaH4pAGCcqvndLq+99lq+973vVR/v3r07zz//fGbOnJk5c+bklltuyT333JPzzz8/c+fOzR133JHZs2dn2bJlozk3ADBO1Rwfzz77bH7rt36r+njVqlVJkuuuuy4PP/xwbr311uzfvz833XRT9u3blyuuuCJbt27N1KlTR29qAGDcqjk+3vOe92R4ePhN99fV1eXuu+/O3XfffUyDAQAnpzF/twsAcGoRHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUNRxi49169blvPPOy9SpU7NgwYI888wzx+tLAQDjyHGJj7/5m7/JqlWrctddd+W5557LxRdfnMWLF+fll18+Hl8OABhHjkt8PPjgg/nDP/zD3HDDDbnwwguzcePG/NIv/VI++9nPHo8vBwCMI5NG+4QHDx5MT09POjo6qmsTJkxIa2truru733D80NBQhoaGqo8HBgaSJIODg6M92gnv8NAPx3oECjoV/x0/lfn5PrWcij/fP/6eh4eHf+6xox4fr7zySl5//fU0NjaOWG9sbMy//du/veH4zs7OfPzjH3/DenNz82iPBieUypqxngA4Xk7ln+9XX301lUrlZx4z6vFRq46Ojqxatar6+PDhw/nf//3fzJo1K3V1dWM4GSUMDg6mubk5vb29aWhoGOtxgFHk5/vUMjw8nFdffTWzZ8/+uceOenycccYZmThxYvr7+0es9/f3p6mp6Q3H19fXp76+fsTajBkzRnssTnANDQ3+4wQnKT/fp46fd8Xjx0b9htMpU6Zk/vz56erqqq4dPnw4XV1daWlpGe0vBwCMM8flZZdVq1bluuuuy6WXXprf+I3fyJo1a7J///7ccMMNx+PLAQDjyHGJjw984AP57//+79x5553p6+vLr//6r2fr1q1vuAkV6uvrc9ddd73hpTdg/PPzzZupG/5F3hMDADBKfLYLAFCU+AAAihIfAEBR4gMAKEp8AABFjfmfV+fU8sorr+Szn/1suru709fXlyRpamrKZZddluuvvz5nnnnmGE8IwPHmygfF7Ny5M29961uzdu3aVCqVXHnllbnyyitTqVSydu3azJs3L88+++xYjwkcJ729vbnxxhvHegxOAP7OB8UsXLgwF198cTZu3PiGDw0cHh7Ohz70ofzzP/9zuru7x2hC4Hh64YUX8s53vjOvv/76WI/CGPOyC8W88MILefjhh4/4acV1dXVZuXJlLrnkkjGYDBgNX/ziF3/m/u9///uFJuFEJz4opqmpKc8880zmzZt3xP3PPPOMP8EP49iyZctSV1eXn3VB/Uj/88GpR3xQzEc/+tHcdNNN6enpyXvf+95qaPT396erqysPPfRQPvnJT47xlMDROvvss7N+/fosXbr0iPuff/75zJ8/v/BUnIjEB8W0t7fnjDPOyOrVq7N+/frq674TJ07M/Pnz8/DDD+f973//GE8JHK358+enp6fnTePj510V4dThhlPGxKFDh/LKK68kSc4444xMnjx5jCcCjtU//uM/Zv/+/fnd3/3dI+7fv39/nn322bz73e8uPBknGvEBABTl73wAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKOr/AbtPFdJs48XWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train dataset into train, validation and test sets"
      ],
      "metadata": {
        "id": "njNJYWgXQSdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, test_text, train_labels, test_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "print('train_text shape =',train_text.shape)\n",
        "print('temp_text shape =',test_text.shape)\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "#                                                                 random_state=2018, \n",
        "#                                                                 test_size=0.5, \n",
        "#                                                                 stratify=temp_labels)\n",
        "\n",
        "# print('val_text shape =',val_text.shape)\n",
        "# print('test_text shape =',test_text.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMXt5LKqzHUJ",
        "outputId": "9e361fc2-a6bd-4f50-85f6-4775f104d52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_text shape = (86,)\n",
            "temp_text shape = (38,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = \"poom-sci/WangchanBERTa-finetuned-sentiment\"#@param [\"poom-sci/WangchanBERTa-finetuned-sentiment\"] "
      ],
      "metadata": {
        "id": "jN5Ttl342Wdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = pretrained"
      ],
      "metadata": {
        "id": "AgMS9t4b2r3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(pretrained)\n",
        "bert = AutoModel.from_pretrained(pretrained)"
      ],
      "metadata": {
        "id": "cwQVP4_YjQki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d38038-feea-4fde-f061-fcce748f5e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at poom-sci/WangchanBERTa-finetuned-sentiment were not used when initializing CamembertModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at poom-sci/WangchanBERTa-finetuned-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRDcnvP22kMd",
        "outputId": "effc065e-efc4-435f-e88a-374f314ca0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiaklEQVR4nO3dfXBU5d3/8c8mbDYE2GCC5EGSGJ8IiuBMMGGLtQJ5EJWCZBSFtsgwOK2BSjJWm45AgrYInQq1E6R2KIwzjVragsUqmIkSxzFBiMMobU2BoRNtSChospA0y97J+f3Rm/3dSxCzyeY6ZPN+zewk5zpnr/36zeXuh7NPDsuyLAEAABgSZXcBAABgeCF8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADBqhN0FXKynp0fNzc0aM2aMHA6H3eUAAIA+sCxLZ8+eVWpqqqKiLn9u44oLH83NzUpLS7O7DAAA0A+fffaZJkyYcNljrrjwMWbMGEn/Ld7tdsvv9+vtt99WQUGBnE6nzdUNH/TdHvTdHvTdHvTdHoPVd6/Xq7S0tMDj+OVcceHjwlMtbrc7ED7i4uLkdrtZnAbRd3vQd3vQd3vQd3sMdt/78pIJXnAKAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjRthdgGnX/vgvdpcwJLiiLW3MkSaX75Ov++u/Hvli/3zu3kGoCgAQCTjzAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKNCDh//+te/9J3vfEeJiYkaOXKkbr31Vh06dCiw37IsrVmzRikpKRo5cqTy8vJ09OjRsBYNAACGrpDCx5dffqkZM2bI6XTqrbfe0t/+9jf94he/0FVXXRU4ZuPGjXrhhRe0detWHThwQKNGjVJhYaG6urrCXjwAABh6RoRy8IYNG5SWlqbt27cHxjIzMwO/W5alzZs36+mnn9a8efMkSS+//LKSkpK0e/duPfTQQ2EqGwAADFUhhY8///nPKiws1AMPPKDa2lpdc801euyxx7R8+XJJ0okTJ9TS0qK8vLzAdeLj45Wbm6u6urpLhg+fzyefzxfY9nq9kiS/3x+4XNgOB1e0FZZ5Ip0rygr6Gapw/b2Gm3Cvd/QNfbcHfbfHYPU9lPkclmX1+dElNjZWklRaWqoHHnhABw8e1OOPP66tW7dqyZIl+uCDDzRjxgw1NzcrJSUlcL0HH3xQDodDr732Wq85y8vLVVFR0Wu8qqpKcXFxff4PAQAA9uns7NSiRYvU3t4ut9t92WNDCh8xMTGaNm2aPvjgg8DYD3/4Qx08eFB1dXX9Ch+XOvORlpam06dPy+12y+/3q7q6Wvn5+XI6nX0t9StNLt834DmGA1eUpWem9Wj1oSj5ehwhX/9IeeEgVBX5wr3e0Tf03R703R6D1Xev16tx48b1KXyE9LRLSkqKbr755qCxSZMm6Y9//KMkKTk5WZLU2toaFD5aW1t12223XXJOl8sll8vVa9zpdAY15eLt/vJ1h/5AOpz5ehz96hl3JAMTrvWO0NB3e9B3e4S776HMFdK7XWbMmKHGxsagsX/84x/KyMiQ9N8XnyYnJ6umpiaw3+v16sCBA/J4PKHcFAAAiFAhnfkoKSnRN77xDf3sZz/Tgw8+qA8//FAvvfSSXnrpJUmSw+HQqlWr9Oyzz+rGG29UZmamVq9erdTUVM2fP38w6gcAAENMSOHj9ttv165du1RWVqZ169YpMzNTmzdv1uLFiwPHPPnkk+ro6NCjjz6qtrY23XHHHdq7d2/gxaoAAGB4Cyl8SNJ9992n++677yv3OxwOrVu3TuvWrRtQYQAAIDLx3S4AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjAopfJSXl8vhcARdsrKyAvu7urpUXFysxMREjR49WkVFRWptbQ170QAAYOgK+czHLbfcopMnTwYu77//fmBfSUmJ9uzZo507d6q2tlbNzc1asGBBWAsGAABD24iQrzBihJKTk3uNt7e3a9u2baqqqtKsWbMkSdu3b9ekSZNUX1+v6dOnD7xaAAAw5IV85uPo0aNKTU3Vddddp8WLF6upqUmS1NDQIL/fr7y8vMCxWVlZSk9PV11dXfgqBgAAQ1pIZz5yc3O1Y8cOTZw4USdPnlRFRYW++c1v6siRI2ppaVFMTIzGjh0bdJ2kpCS1tLR85Zw+n08+ny+w7fV6JUl+vz9wubAdDq5oKyzzRDpXlBX0M1Th+nsNN+Fe7+gb+m4P+m6Pwep7KPM5LMvq96NxW1ubMjIy9Pzzz2vkyJFaunRpUJCQpJycHM2cOVMbNmy45Bzl5eWqqKjoNV5VVaW4uLj+lgYAAAzq7OzUokWL1N7eLrfbfdljQ37Nx/81duxY3XTTTTp27Jjy8/N1/vx5tbW1BZ39aG1tveRrRC4oKytTaWlpYNvr9SotLU0FBQVyu93y+/2qrq5Wfn6+nE7nQMqVJE0u3zfgOYYDV5SlZ6b1aPWhKPl6HCFf/0h54SBUFfnCvd7RN/TdHvTdHoPV9wvPXPTFgMLHuXPndPz4cX33u99Vdna2nE6nampqVFRUJElqbGxUU1OTPB7PV87hcrnkcrl6jTudzqCmXLzdX77u0B9IhzNfj6NfPeOOZGDCtd4RGvpuD/puj3D3PZS5QgofTzzxhObOnauMjAw1Nzdr7dq1io6O1sMPP6z4+HgtW7ZMpaWlSkhIkNvt1sqVK+XxeHinCwAACAgpfHz++ed6+OGHdebMGV199dW64447VF9fr6uvvlqStGnTJkVFRamoqEg+n0+FhYXasmXLoBQOAACGppDCx6uvvnrZ/bGxsaqsrFRlZeWAigIAAJGL73YBAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYNSAwsdzzz0nh8OhVatWBca6urpUXFysxMREjR49WkVFRWptbR1onQAAIEL0O3wcPHhQv/71rzVlypSg8ZKSEu3Zs0c7d+5UbW2tmpubtWDBggEXCgAAIkO/wse5c+e0ePFi/eY3v9FVV10VGG9vb9e2bdv0/PPPa9asWcrOztb27dv1wQcfqL6+PmxFAwCAoatf4aO4uFj33nuv8vLygsYbGhrk9/uDxrOyspSenq66urqBVQoAACLCiFCv8Oqrr+qjjz7SwYMHe+1raWlRTEyMxo4dGzSelJSklpaWS87n8/nk8/kC216vV5Lk9/sDlwvb4eCKtsIyT6RzRVlBP0MVrr/XcBPu9Y6+oe/2oO/2GKy+hzJfSOHjs88+0+OPP67q6mrFxsaGXNilrF+/XhUVFb3G3377bcXFxQW2q6urw3J7G3PCMs2w8cy0nn5d78033wxzJcNLuNY7QkPf7UHf7RHuvnd2dvb5WIdlWX3+p+3u3bt1//33Kzo6OjDW3d0th8OhqKgo7du3T3l5efryyy+Dzn5kZGRo1apVKikp6TXnpc58pKWl6fTp03K73fL7/aqurlZ+fr6cTmef/8O+yuTyfQOeYzhwRVl6ZlqPVh+Kkq/HEfL1j5QXDkJVkS/c6x19Q9/tQd/tMVh993q9GjdunNrb2+V2uy97bEhnPmbPnq1PPvkkaGzp0qXKysrSU089pbS0NDmdTtXU1KioqEiS1NjYqKamJnk8nkvO6XK55HK5eo07nc6gply83V++7tAfSIczX4+jXz3jjmRgwrXeERr6bg/6bo9w9z2UuUIKH2PGjNHkyZODxkaNGqXExMTA+LJly1RaWqqEhAS53W6tXLlSHo9H06dPD+WmAABAhAr5BadfZ9OmTYqKilJRUZF8Pp8KCwu1ZcuWcN8MAAAYogYcPvbv3x+0HRsbq8rKSlVWVg50agAAEIH4bhcAAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUSGFjxdffFFTpkyR2+2W2+2Wx+PRW2+9Fdjf1dWl4uJiJSYmavTo0SoqKlJra2vYiwYAAENXSOFjwoQJeu6559TQ0KBDhw5p1qxZmjdvnv76179KkkpKSrRnzx7t3LlTtbW1am5u1oIFCwalcAAAMDSNCOXguXPnBm3/9Kc/1Ysvvqj6+npNmDBB27ZtU1VVlWbNmiVJ2r59uyZNmqT6+npNnz49fFUDAIAhK6Tw8X91d3dr586d6ujokMfjUUNDg/x+v/Ly8gLHZGVlKT09XXV1dV8ZPnw+n3w+X2Db6/VKkvx+f+ByYTscXNFWWOaJdK4oK+hnqML19xpuwr3e0Tf03R703R6D1fdQ5nNYlhXSo8snn3wij8ejrq4ujR49WlVVVbrnnntUVVWlpUuXBgUJScrJydHMmTO1YcOGS85XXl6uioqKXuNVVVWKi4sLpTQAAGCTzs5OLVq0SO3t7XK73Zc9NuQzHxMnTtThw4fV3t6uP/zhD1qyZIlqa2v7XWxZWZlKS0sD216vV2lpaSooKJDb7Zbf71d1dbXy8/PldDr7fTsXTC7fN+A5hgNXlKVnpvVo9aEo+XocIV//SHnhIFQV+cK93tE39N0e9N0eg9X3C89c9EXI4SMmJkY33HCDJCk7O1sHDx7UL3/5Sy1cuFDnz59XW1ubxo4dGzi+tbVVycnJXzmfy+WSy+XqNe50OoOacvF2f/m6Q38gHc58PY5+9Yw7koEJ13pHaOi7Pei7PcLd91DmGvDnfPT09Mjn8yk7O1tOp1M1NTWBfY2NjWpqapLH4xnozQAAgAgR0pmPsrIyzZkzR+np6Tp79qyqqqq0f/9+7du3T/Hx8Vq2bJlKS0uVkJAgt9utlStXyuPx8E4XAAAQEFL4OHXqlL73ve/p5MmTio+P15QpU7Rv3z7l5+dLkjZt2qSoqCgVFRXJ5/OpsLBQW7ZsGZTCAQDA0BRS+Ni2bdtl98fGxqqyslKVlZUDKgoAAEQuvtsFAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFEhhY/169fr9ttv15gxYzR+/HjNnz9fjY2NQcd0dXWpuLhYiYmJGj16tIqKitTa2hrWogEAwNAVUviora1VcXGx6uvrVV1dLb/fr4KCAnV0dASOKSkp0Z49e7Rz507V1taqublZCxYsCHvhAABgaBoRysF79+4N2t6xY4fGjx+vhoYG3XnnnWpvb9e2bdtUVVWlWbNmSZK2b9+uSZMmqb6+XtOnTw9f5QAAYEgKKXxcrL29XZKUkJAgSWpoaJDf71deXl7gmKysLKWnp6uuru6S4cPn88nn8wW2vV6vJMnv9wcuF7bDwRVthWWeSOeKsoJ+hipcf6/hJtzrHX1D3+1B3+0xWH0PZT6HZVn9enTp6enRt7/9bbW1ten999+XJFVVVWnp0qVBYUKScnJyNHPmTG3YsKHXPOXl5aqoqOg1XlVVpbi4uP6UBgAADOvs7NSiRYvU3t4ut9t92WP7feajuLhYR44cCQSP/iorK1NpaWlg2+v1Ki0tTQUFBXK73fL7/aqurlZ+fr6cTueAbkuSJpfvG/Acw4ErytIz03q0+lCUfD2OkK9/pLxwEKqKfOFe7+gb+m4P+m6Pwer7hWcu+qJf4WPFihV644039N5772nChAmB8eTkZJ0/f15tbW0aO3ZsYLy1tVXJycmXnMvlcsnlcvUadzqdQU25eLu/fN2hP5AOZ74eR796xh3JwIRrvSM09N0e9N0e4e57KHOF9G4Xy7K0YsUK7dq1S++8844yMzOD9mdnZ8vpdKqmpiYw1tjYqKamJnk8nlBuCgAARKiQznwUFxerqqpKr7/+usaMGaOWlhZJUnx8vEaOHKn4+HgtW7ZMpaWlSkhIkNvt1sqVK+XxeHinCwAAkBRi+HjxxRclSXfddVfQ+Pbt2/XII49IkjZt2qSoqCgVFRXJ5/OpsLBQW7ZsCUuxAABg6AspfPTljTGxsbGqrKxUZWVlv4sCAACRi+92AQAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABg1wu4CEJmu/fFf7C5hSHJFW9qYI00u3ydft+Nrj//nc/caqAoAwoszHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADAq5PDx3nvvae7cuUpNTZXD4dDu3buD9luWpTVr1iglJUUjR45UXl6ejh49Gq56AQDAEBdy+Ojo6NDUqVNVWVl5yf0bN27UCy+8oK1bt+rAgQMaNWqUCgsL1dXVNeBiAQDA0Dci1CvMmTNHc+bMueQ+y7K0efNmPf3005o3b54k6eWXX1ZSUpJ2796thx56aGDVAgCAIS/k8HE5J06cUEtLi/Ly8gJj8fHxys3NVV1d3SXDh8/nk8/nC2x7vV5Jkt/vD1wubIeDK9oKyzyRzhVlBf2EGaH2PVz/Xwx34b6fQd/Qd3sMVt9DmS+s4aOlpUWSlJSUFDSelJQU2Hex9evXq6Kiotf422+/rbi4uMB2dXV1WGrcmBOWaYaNZ6b12F3CsNTXvr/55puDXMnwEq77GYSGvtsj3H3v7Ozs87FhDR/9UVZWptLS0sC21+tVWlqaCgoK5Ha75ff7VV1drfz8fDmdzgHf3uTyfQOeYzhwRVl6ZlqPVh+Kkq/HYXc5w0aofT9SXmigqsgX7vsZ9A19t8dg9f3CMxd9EdbwkZycLElqbW1VSkpKYLy1tVW33XbbJa/jcrnkcrl6jTudzqCmXLzdX75uHkhD4etx0DMb9LXv3GGHV7juZxAa+m6PcPc9lLnC+jkfmZmZSk5OVk1NTWDM6/XqwIED8ng84bwpAAAwRIV85uPcuXM6duxYYPvEiRM6fPiwEhISlJ6erlWrVunZZ5/VjTfeqMzMTK1evVqpqamaP39+OOsGAABDVMjh49ChQ5o5c2Zg+8LrNZYsWaIdO3boySefVEdHhx599FG1tbXpjjvu0N69exUbGxu+qgEAwJAVcvi46667ZFlf/TZAh8OhdevWad26dQMqDAAARCa+2wUAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEaNsLsAAP137Y//YncJEcEVbWljjjS5fJ983Y5e+//53L02VAVELs58AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKP4hFMAwBWDT+0dfBc+0ddOnPkAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGDFj4qKyt17bXXKjY2Vrm5ufrwww8H66YAAMAQMijh47XXXlNpaanWrl2rjz76SFOnTlVhYaFOnTo1GDcHAACGkEEJH88//7yWL1+upUuX6uabb9bWrVsVFxen3/72t4NxcwAAYAgJ+yecnj9/Xg0NDSorKwuMRUVFKS8vT3V1db2O9/l88vl8ge329nZJ0hdffCG/3y+/36/Ozk6dOXNGTqdzwPWN+J+OAc8xHIzosdTZ2aMR/ih19zjsLmfYoO/2+Lq+nzlzxoaqIt+l7t+5jx58F9Z7uB5XLzh79qwkybKsr68hbLf6v06fPq3u7m4lJSUFjSclJenTTz/tdfz69etVUVHRazwzMzPcpSFEi+wuYJii7/a4XN/H/cJYGYARg3k/c/bsWcXHx1/2GNu/26WsrEylpaWB7Z6eHn3xxRdKTEyUw+GQ1+tVWlqaPvvsM7ndbhsrHV7ouz3ouz3ouz3ouz0Gq++WZens2bNKTU392mPDHj7GjRun6Ohotba2Bo23trYqOTm51/Eul0sulytobOzYsb2Oc7vdLE4b0Hd70Hd70Hd70Hd7DEbfv+6MxwVhf8FpTEyMsrOzVVNTExjr6elRTU2NPB5PuG8OAAAMMYPytEtpaamWLFmiadOmKScnR5s3b1ZHR4eWLl06GDcHAACGkEEJHwsXLtS///1vrVmzRi0tLbrtttu0d+/eXi9C7QuXy6W1a9f2emoGg4u+24O+24O+24O+2+NK6LvD6st7YgAAAMKE73YBAABGET4AAIBRhA8AAGAU4QMAABh1xYePyspKXXvttYqNjVVubq4+/PBDu0uKaOXl5XI4HEGXrKwsu8uKOO+9957mzp2r1NRUORwO7d69O2i/ZVlas2aNUlJSNHLkSOXl5eno0aP2FBtBvq7vjzzySK/1f/fdd9tTbIRYv369br/9do0ZM0bjx4/X/Pnz1djYGHRMV1eXiouLlZiYqNGjR6uoqKjXB1UiNH3p+1133dVrvX//+983Ut8VHT5ee+01lZaWau3atfroo480depUFRYW6tSpU3aXFtFuueUWnTx5MnB5//337S4p4nR0dGjq1KmqrKy85P6NGzfqhRde0NatW3XgwAGNGjVKhYWF6urqMlxpZPm6vkvS3XffHbT+X3nlFYMVRp7a2loVFxervr5e1dXV8vv9KigoUEfH//8CuZKSEu3Zs0c7d+5UbW2tmpubtWDBAhurHvr60ndJWr58edB637hxo5kCrStYTk6OVVxcHNju7u62UlNTrfXr19tYVWRbu3atNXXqVLvLGFYkWbt27Qps9/T0WMnJydbPf/7zwFhbW5vlcrmsV155xYYKI9PFfbcsy1qyZIk1b948W+oZLk6dOmVJsmpray3L+u/adjqd1s6dOwPH/P3vf7ckWXV1dXaVGXEu7rtlWda3vvUt6/HHH7elniv2zMf58+fV0NCgvLy8wFhUVJTy8vJUV1dnY2WR7+jRo0pNTdV1112nxYsXq6mpye6ShpUTJ06opaUlaO3Hx8crNzeXtW/A/v37NX78eE2cOFE/+MEPdObMGbtLiijt7e2SpISEBElSQ0OD/H5/0HrPyspSeno66z2MLu77Bb/73e80btw4TZ48WWVlZers7DRSj+3favtVTp8+re7u7l6fipqUlKRPP/3UpqoiX25urnbs2KGJEyfq5MmTqqio0De/+U0dOXJEY8aMsbu8YaGlpUWSLrn2L+zD4Lj77ru1YMECZWZm6vjx4/rJT36iOXPmqK6uTtHR0XaXN+T19PRo1apVmjFjhiZPnizpv+s9Jiam1xeKst7D51J9l6RFixYpIyNDqamp+vjjj/XUU0+psbFRf/rTnwa9pis2fMAec+bMCfw+ZcoU5ebmKiMjQ7///e+1bNkyGysDBt9DDz0U+P3WW2/VlClTdP3112v//v2aPXu2jZVFhuLiYh05coTXkRn2VX1/9NFHA7/feuutSklJ0ezZs3X8+HFdf/31g1rTFfu0y7hx4xQdHd3rFc+tra1KTk62qarhZ+zYsbrpppt07Ngxu0sZNi6sb9a+/a677jqNGzeO9R8GK1as0BtvvKF3331XEyZMCIwnJyfr/PnzamtrCzqe9R4eX9X3S8nNzZUkI+v9ig0fMTExys7OVk1NTWCsp6dHNTU18ng8NlY2vJw7d07Hjx9XSkqK3aUMG5mZmUpOTg5a+16vVwcOHGDtG/b555/rzJkzrP8BsCxLK1as0K5du/TOO+8oMzMzaH92dracTmfQem9sbFRTUxPrfQC+ru+XcvjwYUkyst6v6KddSktLtWTJEk2bNk05OTnavHmzOjo6tHTpUrtLi1hPPPGE5s6dq4yMDDU3N2vt2rWKjo7Www8/bHdpEeXcuXNB/7o4ceKEDh8+rISEBKWnp2vVqlV69tlndeONNyozM1OrV69Wamqq5s+fb1/REeByfU9ISFBFRYWKioqUnJys48eP68knn9QNN9ygwsJCG6se2oqLi1VVVaXXX39dY8aMCbyOIz4+XiNHjlR8fLyWLVum0tJSJSQkyO12a+XKlfJ4PJo+fbrN1Q9dX9f348ePq6qqSvfcc48SExP18ccfq6SkRHfeeaemTJky+AXa8h6bEPzqV7+y0tPTrZiYGCsnJ8eqr6+3u6SItnDhQislJcWKiYmxrrnmGmvhwoXWsWPH7C4r4rz77ruWpF6XJUuWWJb137fbrl692kpKSrJcLpc1e/Zsq7Gx0d6iI8Dl+t7Z2WkVFBRYV199teV0Oq2MjAxr+fLlVktLi91lD2mX6rcka/v27YFj/vOf/1iPPfaYddVVV1lxcXHW/fffb508edK+oiPA1/W9qanJuvPOO62EhATL5XJZN9xwg/WjH/3Iam9vN1Kf43+LBAAAMOKKfc0HAACITIQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARv0/jK8YLLgLG8gAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 25"
      ],
      "metadata": {
        "id": "7iH6zO3E24oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "# Parameters max_length = The maximum length (in number of tokens) for the inputs to the transformer model\n",
        "\n",
        "# tokenize and encode sequences in the train set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "# tokens_val = tokenizer.batch_encode_plus(\n",
        "#     val_text.tolist(),\n",
        "#     max_length = max_seq_len,\n",
        "#     pad_to_max_length=True,\n",
        "#     truncation=True,\n",
        "#     return_token_type_ids=False\n",
        "# )\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2nf5QrMLdHi",
        "outputId": "17633e28-bf06-4301-f725-1f9872425ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Integer Sequences to Tensors"
      ],
      "metadata": {
        "id": "81y5IOBMLh66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 input of multihead attention including \n",
        "#1.key = ids\n",
        "#2.query = attention_mask\n",
        "#3.value = label (0,1)\n",
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "# val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "# val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "# val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "MjX3GwMALiHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataLoaders"
      ],
      "metadata": {
        "id": "3eHoXqVGL1aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "# val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "# val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "# val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "DuYUlX3ML12B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UnFreeze BERT Parameters"
      ],
      "metadata": {
        "id": "2KhjM3uBL6E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "dSQM1-fdL35_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model Architecture\n",
        "# Solved error: https://stackoverflow.com/questions/66846030/typeerror-linear-argument-input-position-1-must-be-tensor-not-str"
      ],
      "metadata": {
        "id": "xLntwck-L_Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "# Applies a linear transformation to the incoming data:\n",
        "# Parameters in_features – size of each input sample and out_features – size of each output sample\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)    \n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "PSsDMFd_L_jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "1HhJtJCAMCMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4krN6jdOHmv",
        "outputId": "bcdf4218-a628-407b-a9d4-e687a0c32ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Class Weights"
      ],
      "metadata": {
        "id": "KN6QanHbOIxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights for unbalanced datasets\n",
        "class_wts = compute_class_weight('balanced', classes= np.unique(train_labels), y= train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_u1zDEoOKhQ",
        "outputId": "efcf73ab-4999-4cf1-bcd3-99d6b460d460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.76785714 1.43333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "X1RLglqWON1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune BERT"
      ],
      "metadata": {
        "id": "ckkeghw8OP9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        " \n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "JSq30bEkOR6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "7ltFLoyvOUmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start Model Training**\n"
      ],
      "metadata": {
        "id": "-Y2pFNqkrNUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYfDkjw0rP9O",
        "outputId": "26e87081-8072-4cfc-8ce3-fc84f41344a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.631\n",
            "Validation Loss: 0.615\n",
            "\n",
            " Epoch 2 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.624\n",
            "Validation Loss: 0.597\n",
            "\n",
            " Epoch 3 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.596\n",
            "Validation Loss: 0.578\n",
            "\n",
            " Epoch 4 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.585\n",
            "Validation Loss: 0.559\n",
            "\n",
            " Epoch 5 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.575\n",
            "Validation Loss: 0.541\n",
            "\n",
            " Epoch 6 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.553\n",
            "Validation Loss: 0.521\n",
            "\n",
            " Epoch 7 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.535\n",
            "Validation Loss: 0.501\n",
            "\n",
            " Epoch 8 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.516\n",
            "Validation Loss: 0.489\n",
            "\n",
            " Epoch 9 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.493\n",
            "Validation Loss: 0.472\n",
            "\n",
            " Epoch 10 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.488\n",
            "Validation Loss: 0.459\n",
            "\n",
            " Epoch 11 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.482\n",
            "Validation Loss: 0.447\n",
            "\n",
            " Epoch 12 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.426\n",
            "\n",
            " Epoch 13 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.455\n",
            "Validation Loss: 0.422\n",
            "\n",
            " Epoch 14 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.441\n",
            "Validation Loss: 0.407\n",
            "\n",
            " Epoch 15 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.414\n",
            "Validation Loss: 0.393\n",
            "\n",
            " Epoch 16 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 0.381\n",
            "\n",
            " Epoch 17 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.392\n",
            "Validation Loss: 0.371\n",
            "\n",
            " Epoch 18 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.378\n",
            "Validation Loss: 0.360\n",
            "\n",
            " Epoch 19 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.383\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 20 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.366\n",
            "Validation Loss: 0.337\n",
            "\n",
            " Epoch 21 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.361\n",
            "Validation Loss: 0.329\n",
            "\n",
            " Epoch 22 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.345\n",
            "Validation Loss: 0.313\n",
            "\n",
            " Epoch 23 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.338\n",
            "Validation Loss: 0.307\n",
            "\n",
            " Epoch 24 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.323\n",
            "Validation Loss: 0.296\n",
            "\n",
            " Epoch 25 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.324\n",
            "Validation Loss: 0.295\n",
            "\n",
            " Epoch 26 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.300\n",
            "Validation Loss: 0.283\n",
            "\n",
            " Epoch 27 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.308\n",
            "Validation Loss: 0.268\n",
            "\n",
            " Epoch 28 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.298\n",
            "Validation Loss: 0.261\n",
            "\n",
            " Epoch 29 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.304\n",
            "Validation Loss: 0.254\n",
            "\n",
            " Epoch 30 / 30\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.298\n",
            "Validation Loss: 0.249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load Saved Model**"
      ],
      "metadata": {
        "id": "fjNPDN32rUT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CjmWcfTrne8",
        "outputId": "6d7ac3ba-dd33-4e22-b5f0-b5d96dcaf08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Predictions for Test Data\n"
      ],
      "metadata": {
        "id": "BaatMPCgO0Qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "kyA8E4itOyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVIMAsfwO3DX",
        "outputId": "5669bd93-9501-4d1f-bead-867d87d9b507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        38\n",
            "   macro avg       1.00      1.00      1.00        38\n",
            "weighted avg       1.00      1.00      1.00        38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Predictions for Train Data"
      ],
      "metadata": {
        "id": "5NHSRy0bPAnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(train_seq.to(device), train_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "MS-S5bg7Pe5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(train_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdXBiVn9PEf_",
        "outputId": "88d861b4-2c18-48e3-f01c-4aac0d3f7433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        56\n",
            "           1       1.00      0.93      0.97        30\n",
            "\n",
            "    accuracy                           0.98        86\n",
            "   macro avg       0.98      0.97      0.97        86\n",
            "weighted avg       0.98      0.98      0.98        86\n",
            "\n"
          ]
        }
      ]
    }
  ]
}